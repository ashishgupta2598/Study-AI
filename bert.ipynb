{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\n",
    "       'Hello, how are you? I am Romeo.\\n'\n",
    "       'Hello, Romeo My name is Juliet. Nice to meet you.\\n'\n",
    "       'Nice meet you too. How are you today?\\n'\n",
    "       'Great. My baseball team won the competition.\\n'\n",
    "       'Oh Congratulations, Juliet\\n'\n",
    "       'Thanks you Romeo'\n",
    "   )\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "sentences = re.sub(\"[.,!?\\\\-]\", '', text.lower()).split('\\n')  # filter '.', ',', '?', '!'\n",
    "word_list = list(set(\" \".join(sentences).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hello', 'how', 'are', 'you', 'i', 'am', 'romeo'],\n",
       " ['hello', 'romeo', 'my', 'name', 'is', 'juliet', 'nice', 'to', 'meet', 'you'],\n",
       " ['nice', 'meet', 'you', 'too', 'how', 'are', 'you', 'today'],\n",
       " ['great', 'my', 'baseball', 'team', 'won', 'the', 'competition'],\n",
       " ['oh', 'congratulations', 'juliet'],\n",
       " ['thanks', 'you', 'romeo']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list = [i.split() for i in sentences]\n",
    "token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3,0:0,1:1,2:2,3:3}\n",
    "for i,w in enumerate(word_list):\n",
    "   word_dict[w] = i + 4\n",
    "   number_dict = {i: w for i, w in enumerate(word_dict)}\n",
    "vocab_size = len(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33,\n",
       " {0: '[PAD]',\n",
       "  1: '[CLS]',\n",
       "  2: '[SEP]',\n",
       "  3: '[MASK]',\n",
       "  4: 0,\n",
       "  5: 1,\n",
       "  6: 2,\n",
       "  7: 3,\n",
       "  8: 'how',\n",
       "  9: 'too',\n",
       "  10: 'to',\n",
       "  11: 'thanks',\n",
       "  12: 'juliet',\n",
       "  13: 'you',\n",
       "  14: 'baseball',\n",
       "  15: 'congratulations',\n",
       "  16: 'i',\n",
       "  17: 'team',\n",
       "  18: 'oh',\n",
       "  19: 'romeo',\n",
       "  20: 'is',\n",
       "  21: 'name',\n",
       "  22: 'competition',\n",
       "  23: 'the',\n",
       "  24: 'today',\n",
       "  25: 'great',\n",
       "  26: 'are',\n",
       "  27: 'meet',\n",
       "  28: 'hello',\n",
       "  29: 'nice',\n",
       "  30: 'am',\n",
       "  31: 'won',\n",
       "  32: 'my'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size,number_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 14, 11, 8, 2, 24, 4, 22, 9, 12, 26, 15, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randrange,shuffle,randint\n",
    "tokens_a_index, tokens_b_index= randrange(len(sentences)), randrange(len(sentences)) \n",
    "tokens_a, tokens_b= token_list[tokens_a_index], token_list[tokens_b_index]\n",
    "\n",
    "input_ids = [word_dict['[CLS]']] + tokens_a + [word_dict['[SEP]']] + tokens_b + [word_dict['[SEP]']] #token embeeing kind\n",
    "input_ids =  [word_dict[i] for i in input_ids if i in word_dict] \n",
    "segment_ids = [0] * (1 + len(tokens_a) + 1) + [1] * (len(tokens_b) + 1)\n",
    "\n",
    "\n",
    "segment_ids,input_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'how', 'are', 'you', 'i', 'am', 'romeo']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pred = 8\n",
    "n_pred =  min(max_pred, max(1, int(round(len(input_ids) * 0.15))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 7, 9, 5, 6, 1, 2, 11, 10, 3]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand_maked_pos = [i for i, token in enumerate(input_ids)\n",
    "                         if token != word_dict['[CLS]'] and token != word_dict['[SEP]']]\n",
    "shuffle(cand_maked_pos)\n",
    "cand_maked_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 11, 8, 2, 24, 4, 22, 3, 12, 26, 15, 2]\n",
      "[1, 14, 11, 8, 2, 24, 4, 3, 3, 12, 26, 15, 2]\n"
     ]
    }
   ],
   "source": [
    "masked_tokens, masked_pos = [], []\n",
    "import random\n",
    "rand = random.Random()\n",
    "for pos in cand_maked_pos[:n_pred]:  \n",
    "           masked_pos.append(pos)\n",
    "           masked_tokens.append(input_ids[pos])\n",
    "           ran1 = rand.uniform(0.5,0.8)\n",
    "           if   ran1< 0.8 and ran1>0.5:  # 80%\n",
    "               input_ids[pos] = word_dict['[MASK]'] # make mask?\n",
    "               print(input_ids)\n",
    "           elif rand.uniform(0,1) < 0.5:  # 10%-----> replacing one word with random word...\n",
    "               print(\"hello i am masking\")\n",
    "               index = randint(0, vocab_size - 1) # random index in vocabulary\n",
    "               input_ids[pos] = word_dict[number_dict[index]] # replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 128\n",
    "n_pad = maxlen - len(input_ids)\n",
    "input_ids.extend([0] * n_pad)\n",
    "segment_ids.extend([0] * n_pad)\n",
    "if max_pred > n_pred:\n",
    "           n_pad = max_pred - n_pred\n",
    "           masked_tokens.extend([0] * n_pad)\n",
    "           masked_pos.extend([0] * n_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_ids = segment_ids[:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange,shuffle,randint\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import randrange,shuffle\n",
    "batch_size = 2\n",
    "def make_batch():\n",
    "   batch = []\n",
    "   positive = negative = 0\n",
    "   while positive != batch_size/2 or negative != batch_size/2:#getting half -ve and half positive sentence \n",
    "       tokens_a_index, tokens_b_index= randrange(len(sentences)), randrange(len(sentences)) \n",
    "       \n",
    "       tokens_a, tokens_b= token_list[tokens_a_index], token_list[tokens_b_index]\n",
    "    #    print(tokens_a,tokens_b)\n",
    "\n",
    "       input_ids = [word_dict['[CLS]']] + tokens_a + [word_dict['[SEP]']] + tokens_b + [word_dict['[SEP]']] #token embeeing kind\n",
    "       input_ids =  [word_dict[i] for i in input_ids if i in word_dict] \n",
    "       segment_ids = [0] * (1 + len(tokens_a) + 1) + [1] * (len(tokens_b) + 1)\n",
    " \n",
    "       # MASK LM\n",
    "       cand_maked_pos = [i for i, token in enumerate(input_ids)\n",
    "                         if token != word_dict['[CLS]'] and token != word_dict['[SEP]']]\n",
    "       shuffle(cand_maked_pos)\n",
    "       cand_maked_pos\n",
    "       \n",
    "       masked_tokens, masked_pos = [], []\n",
    "       import random\n",
    "       rand = random.Random()\n",
    "       for pos in cand_maked_pos[:n_pred]:  \n",
    "           masked_pos.append(pos)\n",
    "           masked_tokens.append(input_ids[pos])\n",
    "           ran1 = rand.uniform(0.5,0.8)\n",
    "           if   ran1< 0.8 and ran1>0.5:  # 80%\n",
    "               input_ids[pos] = word_dict['[MASK]'] # make mask?\n",
    "               #print(input_ids)\n",
    "           elif rand.uniform(0,1) < 0.5:  # 10%-----> replacing one word with random word...\n",
    "               #print(\"hello i am masking\")\n",
    "               index = randint(0, vocab_size - 1) # random index in vocabulary\n",
    "               input_ids[pos] = word_dict[number_dict[index]] # replace\n",
    "        # \"\"\"\n",
    "        # from line 25 to 32 we are adding mask to our vocabs\n",
    "        # \"\"\"\n",
    "\n",
    "       # Zero Paddings\n",
    "       maxlen = 128\n",
    "       n_pad = maxlen - len(input_ids)\n",
    "       input_ids.extend([0] * n_pad)\n",
    "       segment_ids.extend([0] * n_pad)\n",
    "       if max_pred > n_pred:\n",
    "           n_pad = max_pred - n_pred\n",
    "           masked_tokens.extend([0] * n_pad)\n",
    "           masked_pos.extend([0] * n_pad)\n",
    "        \n",
    "        #i got my sentence to my neural net ready...2 sent to 1 sent with pad,cls,slp etc tokens\n",
    "        #and i get segment ids, maked tokens, maskes token positons with padding to max size\n",
    "\n",
    "        #\"\"\"\n",
    "        # if (3,2 is the pair) then it falls into negative sent as sent 2 dint come next to sent 3. but if (2,3) then its a positive sentece\n",
    "        #\"\"\"\n",
    "       if tokens_a_index + 1 == tokens_b_index and positive < batch_size/2:\n",
    "           batch.append([input_ids, segment_ids, masked_tokens, masked_pos, True]) # IsNext\n",
    "           positive += 1\n",
    "       elif tokens_a_index + 1 != tokens_b_index and negative < batch_size/2:\n",
    "           batch.append([input_ids, segment_ids, masked_tokens, masked_pos, False]) # NotNext\n",
    "           negative += 1\n",
    "       return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "btch = make_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 13, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btch[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.arange(128, dtype=torch.long).expand_as(torch.tensor(input_ids)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 28, 19,  3,  5, 24,  4, 18,  2, 28,  3, 15, 11, 27, 17, 20, 25,  8,\n",
       "          5,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN WORK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "d_model = 264\n",
    "n_segments = 2\n",
    "class Embedding(nn.Module):\n",
    "   def __init__(self):\n",
    "       super(Embedding, self).__init__()\n",
    "       self.tok_embed = nn.Embedding(vocab_size, d_model)  # token embedding\n",
    "       self.pos_embed = nn.Embedding(maxlen, d_model)  # position embedding\n",
    "       self.seg_embed = nn.Embedding(n_segments, d_model)  # segment(token type) embedding\n",
    "       self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "   def forward(self, x, seg):\n",
    "       seq_len = x.size(1)\n",
    "       pos = torch.arange(seq_len, dtype=torch.long)\n",
    "       #print(pos.shape,x.shape,seg.shape)\n",
    "       pos = pos.unsqueeze(0).expand_as(x)  # (seq_len,) -> (batch_size, seq_len)\n",
    "       embedding = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)\n",
    "       return self.norm(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-117-89a70f0cb947>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids,segment_ids = torch.tensor(input_ids).view(1,-1),torch.tensor(segment_ids).view(1,-1)\n",
      "<ipython-input-117-89a70f0cb947>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  enc_input = emb_nn(torch.tensor(input_ids),torch.tensor(segment_ids))\n"
     ]
    }
   ],
   "source": [
    "emb_nn = Embedding()\n",
    "input_ids,segment_ids = torch.tensor(input_ids).view(1,-1),torch.tensor(segment_ids).view(1,-1)\n",
    "enc_input = emb_nn(torch.tensor(input_ids),torch.tensor(segment_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True]) tensor([ 1, 14, 11,  8,  2, 24,  4,  3,  3, 12, 26, 15,  2,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0])\n"
     ]
    }
   ],
   "source": [
    "def get_attn_pad_mask(seq_q, seq_k):#for padding purposes\n",
    "   batch_size, len_q = seq_q.size()\n",
    "   batch_size, len_k = seq_k.size()\n",
    "   # eq(zero) is PAD token\n",
    "   pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # batch_size x 1 x len_k(=len_q), one is masking\n",
    "   return pad_attn_mask.expand(batch_size, len_q, len_k)  # batch_size x len_q x len_k-->batch_size x no_heads x len_q x len_k\n",
    "print(get_attn_pad_mask(input_ids, input_ids)[0][0], input_ids[0])\n",
    "#print(tor)\n",
    "attn_mask = get_attn_pad_mask(input_ids, input_ids)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "   def __init__(self):\n",
    "       super(EncoderLayer, self).__init__()\n",
    "       self.enc_self_attn = MultiHeadAttention()\n",
    "       self.pos_ffn = PoswiseFeedForwardNet()\n",
    "\n",
    "   def forward(self, enc_inputs, enc_self_attn_mask):\n",
    "       enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) # enc_inputs to same Q,K,V\n",
    "       enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size x len_q x d_model]\n",
    "       return enc_outputs, attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These three inputs and the attention mask are operated with a dot product operation that yields two outputs: \n",
    "context vectors and attention. The context vector is then passed through a linear layer and finally that yields the output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import SCORERS\n",
    "\n",
    "\n",
    "n_heads,d_k,d_v = 8,64,64\n",
    "class MultiHeadAttention(nn.Module):\n",
    "   def __init__(self):\n",
    "       super(MultiHeadAttention, self).__init__()\n",
    "       self.W_Q = nn.Linear(d_model, d_k * n_heads) #42--->7...6 heads---> 42\n",
    "       self.W_K = nn.Linear(d_model, d_k * n_heads)\n",
    "       self.W_V = nn.Linear(d_model, d_v * n_heads) #element wise product\n",
    "\n",
    "   def forward(self, Q, K, V, attn_mask):\n",
    "        #Q, K, V,-->seq input sentence--->[batch,seq_l,d_model]\n",
    "       # q: [batch_size x len_q x d_model], k: [batch_size x len_k x d_model], v: [batch_size x len_k x d_model]\n",
    "       residual, batch_size = Q, Q.size(0)\n",
    "       # (B, S, D) -proj-> (B, S, D) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n",
    "       q_s = self.W_Q(Q).view(batch_size, -1, n_heads, d_k).transpose(1,2)  # q_s: [batch_size x n_heads x len_q x d_k]\n",
    "       k_s = self.W_K(K).view(batch_size, -1, n_heads, d_k).transpose(1,2)  # k_s: [batch_size x n_heads x len_k x d_k]\n",
    "       v_s = self.W_V(V).view(batch_size, -1, n_heads, d_v).transpose(1,2)  # v_s: [batch_size x n_heads x len_k x d_v]\n",
    "       #attn_mask-->batch_s*num_seq\n",
    "       attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1) # attn_mask : [batch_size x n_heads x len_q x len_k]\n",
    "       # context: [batch_size x n_heads x len_q x d_v], attn: [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "       context, attn,scores = ScaledDotProductAttention()(q_s, k_s, v_s, attn_mask)\n",
    "       context = context.transpose(1, 2).contiguous().view(batch_size, -1, n_heads * d_v) # context: [batch_size x len_q x n_heads * d_v]\n",
    "       output = nn.Linear(n_heads * d_v, d_model)(context)\n",
    "       return nn.LayerNorm(d_model)(output + residual), attn # output: [batch_size x len_q x d_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-55e8e42b2bf0>:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  nn.Softmax()(arr)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 2.0612e-09, 2.7895e-10, 1.0000e+00, 1.0262e-10, 1.8942e-15,\n",
       "        1.7139e-15])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = torch.tensor(([-1e5,14,12,34,11,0.1,0]))\n",
    "nn.Softmax()(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "   def __init__(self):\n",
    "       super(ScaledDotProductAttention, self).__init__()\n",
    "   def forward(self, Q, K, V, attn_mask):\n",
    "       scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k) # scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "       #################\n",
    "       \n",
    "       scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is one.\n",
    "       ###why this upper line...scores..(why -1e9)\n",
    "       attn = nn.Softmax(dim=-1)(scores)\n",
    "\n",
    "       context = torch.matmul(attn, V)  \n",
    "       return context, attn,scores\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.8446e-01, -1.3233e-01, -5.7382e-01, -3.8168e-01,  2.7246e-03,\n",
       "         5.5001e-02, -5.2757e-01, -1.0408e-01, -6.6770e-02, -2.8307e-01,\n",
       "        -9.5595e-02,  1.5389e-01,  2.0026e-01, -1.0000e+09, -1.0000e+09,\n",
       "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores1 = score\n",
    "attn_mask\n",
    "scores1.masked_fill_(attn_mask, -1e9)[0][0][0][:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = MultiHeadAttention()\n",
    "attn_output,att,score = attention(enc_input,enc_input,enc_input,attn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 264])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "      super(PoswiseFeedForwardNet, self).__init__() #264\n",
    "      self.fc1 = nn.Linear(d_model,d_model)\n",
    "      self.norm = nn.LayerNorm(d_model)\n",
    "    def forward(self,ip):\n",
    "      return self.norm(self.fc1(ip)+ip)\n",
    "ffn = PoswiseFeedForwardNet()\n",
    "ffn(attn_output).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Study-AI'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ashishgupta2598/Study-AI.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 4, 6])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.randn(2, 3,5,6,7)\n",
    "x = torch.transpose(x, 1, 4)\n",
    "x.shape\n",
    "x = torch.tensor([[1, 2, 3],[7,8,9]])\n",
    "print(x.shape)\n",
    "x.repeat(4,3,2,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return F.gelu(input)\n",
    "import math\n",
    "def gelu(x):\n",
    "   return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 12\n",
    "class BERT(nn.Module):\n",
    "   def __init__(self):\n",
    "       super(BERT, self).__init__()\n",
    "       self.embedding = Embedding()\n",
    "       self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n",
    "       self.fc = nn.Linear(d_model, d_model)\n",
    "       self.activ1 = nn.Tanh()\n",
    "       self.linear = nn.Linear(d_model, d_model)\n",
    "       self.activ2 = GELU()\n",
    "       self.norm = nn.LayerNorm(d_model)\n",
    "       self.classifier = nn.Linear(d_model, 2) #weather its next sentence or not of first sentence\n",
    "\n",
    "       # decoder is shared with embedding layer\n",
    "       embed_weight = self.embedding.tok_embed.weight\n",
    "       n_vocab, n_dim = embed_weight.size()\n",
    "       self.decoder = nn.Linear(n_dim, n_vocab, bias=False)\n",
    "       self.decoder.weight = embed_weight\n",
    "       self.decoder_bias = nn.Parameter(torch.zeros(n_vocab))\n",
    "\n",
    "   def forward(self, input_ids, segment_ids, masked_pos):\n",
    "       output = self.embedding(input_ids, segment_ids)\n",
    "       enc_self_attn_mask = get_attn_pad_mask(input_ids, input_ids)\n",
    "       for layer in self.layers:\n",
    "           output, enc_self_attn = layer(output, enc_self_attn_mask)\n",
    "       # output : [batch_size, len, d_model], attn : [batch_size, n_heads, d_mode, d_model]\n",
    "       # it will be decided by first token(CLS)\n",
    "       h_pooled = self.activ1(self.fc(output[:, 0])) # [batch_size, d_model]\n",
    "       logits_clsf = self.classifier(h_pooled) # [batch_size, 2]\n",
    "\n",
    "\n",
    "        ###final masked positions\n",
    "        \n",
    "       masked_pos = masked_pos[:, :, None].expand(-1, -1, output.size(-1)) # [batch_size, max_pred, d_model]\n",
    "\n",
    "       # get masked position from final output of transformer.\n",
    "       h_masked = torch.gather(output, 1, masked_pos) # masking position [batch_size, max_pred, d_model]\n",
    "       h_masked = self.norm(self.activ2(self.linear(h_masked)))\n",
    "       logits_lm = self.decoder(h_masked) + self.decoder_bias # [batch_size, max_pred, n_vocab]\n",
    "\n",
    "       return logits_lm, logits_clsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 264])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 264])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masked_pos = mk[:, :, None].expand(-1, -1, 264)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 264])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8)\n",
      "tensor(13)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "arr = []\n",
    "for i in mk[0]:\n",
    "    print(i)\n",
    "    arr.append(enc_input[0][i])\n",
    "arr1 = torch.stack(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7482, -0.6406,  2.3126,  ...,  1.3393, -1.0581, -1.0358],\n",
       "        [-0.5056,  1.3264,  2.1279,  ...,  0.5359, -1.7751,  0.8639],\n",
       "        [ 0.7458,  0.9808,  1.7282,  ..., -0.4824, -0.9228,  0.8545],\n",
       "        ...,\n",
       "        [ 0.7458,  0.9808,  1.7282,  ..., -0.4824, -0.9228,  0.8545],\n",
       "        [ 0.7458,  0.9808,  1.7282,  ..., -0.4824, -0.9228,  0.8545],\n",
       "        [ 0.7458,  0.9808,  1.7282,  ..., -0.4824, -0.9228,  0.8545]],\n",
       "       grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7482, -0.6406,  2.3126,  ...,  1.3393, -1.0581, -1.0358],\n",
       "         [-0.5056,  1.3264,  2.1279,  ...,  0.5359, -1.7751,  0.8639],\n",
       "         [ 0.7458,  0.9808,  1.7282,  ..., -0.4824, -0.9228,  0.8545],\n",
       "         ...,\n",
       "         [ 0.7458,  0.9808,  1.7282,  ..., -0.4824, -0.9228,  0.8545],\n",
       "         [ 0.7458,  0.9808,  1.7282,  ..., -0.4824, -0.9228,  0.8545],\n",
       "         [ 0.7458,  0.9808,  1.7282,  ..., -0.4824, -0.9228,  0.8545]]],\n",
       "       grad_fn=<GatherBackward>)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(enc_input, 1, masked_pos) # masking position [batch_size, max_pred, d_model]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 264])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_pos[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk = torch.tensor([btch[0][3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8, 13,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "from torch import optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128]) torch.Size([1, 128]) torch.Size([1, 8]) torch.Size([1, 8]) tensor([1])\n"
     ]
    }
   ],
   "source": [
    "model = BERT()\n",
    "batch = make_batch()\n",
    "input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(*batch))\n",
    "print(input_ids.shape, segment_ids.shape, masked_tokens.shape, masked_pos.shape, isNext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0010 cost = 36.806892\n",
      "Epoch: 0020 cost = 44.657158\n",
      "Epoch: 0030 cost = 26.927658\n",
      "Epoch: 0040 cost = 51.918751\n",
      "Epoch: 0050 cost = 37.517300\n",
      "Epoch: 0060 cost = 38.391052\n",
      "Epoch: 0070 cost = 46.027973\n",
      "Epoch: 0080 cost = 40.382893\n",
      "Epoch: 0090 cost = 72.925652\n",
      "Epoch: 0100 cost = 39.761505\n",
      "Epoch: 0110 cost = 50.296665\n",
      "Epoch: 0120 cost = 53.890007\n",
      "Epoch: 0130 cost = 44.961403\n",
      "Epoch: 0140 cost = 55.985207\n",
      "Epoch: 0150 cost = 64.352257\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-174-36a044757707>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#    batch = make_batch()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#    input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(*batch))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m        \u001b[0mlogits_lm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits_clsf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasked_pos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m        \u001b[0mloss_lm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits_lm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasked_tokens\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# for masked LM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m        \u001b[0mloss_lm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mloss_lm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASHISH\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-170-85160a928795>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, segment_ids, masked_pos)\u001b[0m\n\u001b[0;32m     23\u001b[0m        \u001b[0menc_self_attn_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_attn_pad_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m        \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m            \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_self_attn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_self_attn_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m        \u001b[1;31m# output : [batch_size, len, d_model], attn : [batch_size, n_heads, d_mode, d_model]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m        \u001b[1;31m# it will be decided by first token(CLS)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASHISH\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-169-4aeee914d089>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, enc_inputs, enc_self_attn_mask)\u001b[0m\n\u001b[0;32m      7\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_self_attn_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m        \u001b[0menc_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menc_self_attn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_self_attn_mask\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# enc_inputs to same Q,K,V\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m        \u001b[0menc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_ffn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_outputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# enc_outputs: [batch_size x len_q x d_model]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0menc_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASHISH\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-91-d042b27d3737>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, ip)\u001b[0m\n\u001b[0;32m      5\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mffn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPoswiseFeedForwardNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mffn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1121):\n",
    "       optimizer.zero_grad()\n",
    "    #    batch = make_batch()\n",
    "    #    input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(*batch))\n",
    "       logits_lm, logits_clsf = model(input_ids, segment_ids, masked_pos)\n",
    "       loss_lm = criterion(logits_lm.transpose(1, 2), masked_tokens) # for masked LM\n",
    "       loss_lm = (loss_lm.float()).mean()\n",
    "       loss_clsf = criterion(logits_clsf, isNext) # for sentence classification\n",
    "       loss = loss_lm + loss_clsf\n",
    "       if (epoch + 1) % 10 == 0:\n",
    "           print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
    "       loss.backward()\n",
    "       optimizer.step()\n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello-------ṭ  Hello, how are you? I am Romeo.\n",
      "Hello, Romeo My name is Juliet. Nice to meet you.\n",
      "Nice meet you too. How are you today?\n",
      "Great. My baseball team won the competition.\n",
      "Oh Congratulations, Juliet\n",
      "Thanks you Romeo\n",
      "['[CLS]', 'won', 'am', 1, 'you', '[MASK]', 'too', 1, 'meet', '[SEP]', 'i', 'my', 'too', 1, '[MASK]', 0, 'great', '[SEP]']\n",
      "masked tokens list :  [19, 24]\n",
      "predict masked tokens list :  [10, 30, 27, 27, 27, 27, 27, 27]\n",
      "isNext :  False\n",
      "predict isNext :  True\n"
     ]
    }
   ],
   "source": [
    "batch = make_batch()\n",
    "input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(batch[0]))\n",
    "print(\"hello-------ṭ \",text)\n",
    "print([number_dict[w.item()] for w in input_ids[0] if number_dict[w.item()] != '[PAD]'])\n",
    "\n",
    "logits_lm, logits_clsf = model(input_ids, segment_ids, masked_pos)\n",
    "logits_lm = logits_lm.data.max(2)[1][0].data.numpy()\n",
    "print('masked tokens list : ',[pos.item() for pos in masked_tokens[0] if pos.item() != 0])\n",
    "print('predict masked tokens list : ',[pos for pos in logits_lm if pos != 0])\n",
    "\n",
    "logits_clsf = logits_clsf.data.max(1)[1].data.numpy()[0]\n",
    "print('isNext : ', True if isNext else False)\n",
    "print('predict isNext : ',True if logits_clsf else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7cfccb1c4a066d62071c49aa6393a0052d539a6d2e5142ea588cae5706c4b62"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
